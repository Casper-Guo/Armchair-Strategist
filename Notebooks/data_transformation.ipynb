{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tomli\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s\t%(filename)s\t%(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = Path.cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(parent_path / \"Data\" / \"compound_selection.toml\", \"rb\") as toml:\n",
    "    compound_selection = tomli.load(toml)\n",
    "with open(parent_path / \"Data\" / \"visualization_config.toml\", \"rb\") as toml:\n",
    "    visual_config = tomli.load(toml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress SettingWithCopy Warning\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Read csv file at path location and filter for relevant columns.\n",
    "\n",
    "    Requires:\n",
    "        csv file located at path location is derived from a fastf1 laps object.\n",
    "\n",
    "    Args:\n",
    "        path: The path to the csv file containing partial season data.\n",
    "\n",
    "    Returns:\n",
    "        A pandas dataframe object.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(\n",
    "        path,\n",
    "        header=0,\n",
    "        true_values=[\"TRUE\"],\n",
    "        false_values=[\"FALSE\"],\n",
    "        usecols=[\n",
    "            \"Time\",\n",
    "            \"DriverNumber\",\n",
    "            \"LapTime\",\n",
    "            \"LapNumber\",\n",
    "            \"Stint\",\n",
    "            \"PitOutTime\",\n",
    "            \"PitInTime\",\n",
    "            \"IsPersonalBest\",\n",
    "            \"Compound\",\n",
    "            \"TyreLife\",\n",
    "            \"FreshTyre\",\n",
    "            \"Team\",\n",
    "            \"Driver\",\n",
    "            \"TrackStatus\",\n",
    "            \"Position\",\n",
    "            \"IsAccurate\",\n",
    "            \"RoundNumber\",\n",
    "            \"EventName\",\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_dtype(df_laps: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Fix some columns where the data types are incorrectly parsed or where there are missing values.\n",
    "\n",
    "    Requires:\n",
    "        df_laps has the following columns: [`Time`, `LapTime`, `PitInTime`, `PitOutTime`, `IsPersonalBest`]\n",
    "\n",
    "    Effects:\n",
    "        - Cast all timing columns to timedelta type\n",
    "        - Convert the `LapTime` column to integer type\n",
    "        - Infer missing `IsPersonalBest` values as False\n",
    "\n",
    "    Returns:\n",
    "        The transformed dataframe.\n",
    "    \"\"\"\n",
    "    # convert from object (string) to timedelta\n",
    "    df_laps[[\"Time\", \"LapTime\", \"PitInTime\", \"PitOutTime\"]] = df_laps[\n",
    "        [\"Time\", \"LapTime\", \"PitInTime\", \"PitOutTime\"]\n",
    "    ].apply(pd.to_timedelta)\n",
    "    df_laps[\"LapTime\"] = df_laps[\"LapTime\"].apply(lambda x: x.total_seconds())\n",
    "\n",
    "    # convert from object (string) to bool\n",
    "    # treat missing entries as False\n",
    "    df_laps[\"IsPersonalBest\"] = df_laps[\"IsPersonalBest\"].fillna(value=\"False\")\n",
    "    df_laps[\"IsPersonalBest\"] = df_laps[\"IsPersonalBest\"].astype(bool)\n",
    "\n",
    "    return df_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_compound(df_laps: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Infer missing `Compound` values as `UNKNOWN`.\n",
    "\n",
    "    Requires:\n",
    "        df_laps has the `Compound` column.\n",
    "    \"\"\"\n",
    "    df_laps[\"Compound\"] = df_laps[\"Compound\"].fillna(value=\"UNKNOWN\")\n",
    "\n",
    "    return df_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_laps() -> dict[int, dict[str, pd.DataFrame]]:\n",
    "    \"\"\"Parse through a directory of data csvs and store them in a dictionary by season and type.\n",
    "\n",
    "    Examples:\n",
    "        - all_laps_2023.csv\n",
    "        - all_laps_2022.csv\n",
    "        - transformed_laps_2022.csv\n",
    "        - transformed_laps_2021.csv\n",
    "\n",
    "        reads to\n",
    "        {\n",
    "            2023: {\"all\": df}\n",
    "            2022: {\"all\": df, \"transformed\": df}\n",
    "            2021: {\"transformed\": df}\n",
    "        }\n",
    "    \"\"\"\n",
    "    df_dict = {}\n",
    "\n",
    "    for file in Path.iterdir(parent_path / \"Data\"):\n",
    "        if file.suffix == \".csv\":\n",
    "            splits = file.stem.split(\"_\")\n",
    "\n",
    "            # \"all\" or \"transformed\"\n",
    "            type = splits[0]\n",
    "            season = int(splits[2])\n",
    "\n",
    "            df = read_csv(file)\n",
    "\n",
    "            if type == \"all\":\n",
    "                correct_dtype(df)\n",
    "                fill_compound(df)\n",
    "\n",
    "            if season not in df_dict:\n",
    "                df_dict[season] = {}\n",
    "\n",
    "            df_dict[season][type] = df\n",
    "\n",
    "    return df_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Tyre Information Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_is_slick(season: int, df_laps: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add a `IsSlick` column to df_laps in place.\n",
    "\n",
    "    All compounds that are not intermediate or wet are considered slick.\n",
    "\n",
    "    Requires:\n",
    "        df_laps has the `Compound` column.\n",
    "\n",
    "    Returns:\n",
    "        The modified dataframe.\n",
    "    \"\"\"\n",
    "    slick_names = []\n",
    "\n",
    "    if season == 2018:\n",
    "        slick_names = visual_config[\"slick_names\"][\"18\"]\n",
    "    else:\n",
    "        slick_names = visual_config[\"slick_names\"][\"19_\"]\n",
    "\n",
    "    df_laps[\"IsSlick\"] = df_laps[\"Compound\"].apply(lambda x: x in slick_names)\n",
    "\n",
    "    return df_laps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastF1 provides relative compound information (soft, medium, hard) as the `Compound` column in its `Laps` objects\n",
    "\n",
    "The actual compound names (C1, C2, C3 etc. or ultrasoft, supersoft etc.) needs to be added to maintain consistency. These will be recorded in the `CompoundName` column.\n",
    "\n",
    "For the 2018 season, the `Compound` column already records the actual compound names. The `CompoundName` column will still be added for consistency.\n",
    "\n",
    "To further ensure consistency, the 2018 `Compound` column will be converted so it also has the (soft, medium, hard) representation. **Before** this transformation is applied, the 2018 `Compound` and `CompoundName` columns are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_compound_name(\n",
    "    df_laps: pd.DataFrame,\n",
    "    compound_selection: dict[int, dict[int, list[str]]],\n",
    "    season: int,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Infer the underlying compound names and add it to df_laps in place.\n",
    "\n",
    "    Args:\n",
    "        df_laps: A pandas dataframe containing data from a single season.\n",
    "        compound_selection: A dictionary describing the underlying slick compounds selected by Grand Prix round number, in the order from the softest to hardest.\n",
    "        season: The season to which df_laps and compound_selection must both be referring to.\n",
    "\n",
    "    Requires:\n",
    "        df_laps has the following columns: [`Compound`, `RoundNumber`]\n",
    "\n",
    "    Returns:\n",
    "        The modified dataframe.\n",
    "    \"\"\"\n",
    "    if season == 2018:\n",
    "        df_laps[\"CompoundName\"] = df_laps[\"Compound\"]\n",
    "\n",
    "        return df_laps\n",
    "\n",
    "    def convert_compound_name(row):\n",
    "        compound_to_index = {\"SOFT\": 2, \"MEDIUM\": 1, \"HARD\": 0}\n",
    "\n",
    "        try:\n",
    "            if row.loc[\"Compound\"] not in compound_to_index:\n",
    "                return row.loc[\"Compound\"]\n",
    "            else:\n",
    "                return compound_selection[str(row.loc[\"RoundNumber\"])][\n",
    "                    compound_to_index[row.loc[\"Compound\"]]\n",
    "                ]\n",
    "        except KeyError:\n",
    "            # error handling for when compound_selection.toml is not up-to-date\n",
    "            logging.error(\n",
    "                \"Compound selection record is missing for round \"\n",
    "                + str(row.loc[\"RoundNumber\"])\n",
    "            )\n",
    "\n",
    "            # terminate cell\n",
    "            assert False\n",
    "\n",
    "    df_laps[\"CompoundName\"] = df_laps.apply(convert_compound_name, axis=1)\n",
    "\n",
    "    return df_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_compound(df_laps: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add the relative compound names (SOFT, MEDIUM, HARD) to 2018 data in place.\n",
    "\n",
    "    The 2018 data only has the underlying compound names (ultrasoft etc.) but sometimes we want access to the relative compound names as well.\n",
    "\n",
    "    Args:\n",
    "        df_laps: A pandas dataframe containing data from the 2018 season.\n",
    "\n",
    "    Requires:\n",
    "        df_laps has the following columns: [1Compound1, `RoundNumber`].\n",
    "\n",
    "    Example:\n",
    "        2018 round 1 uses the following compound selection:\n",
    "        [\"ULTRASOFT\", \"SUPERSOFT\", \"SOFT\"]\n",
    "        So the following mapping is applied:\n",
    "        {\n",
    "            \"ULTRASOFT\": \"SOFT\",\n",
    "            \"SUPERSOFT\": \"MEDIUM\",\n",
    "            \"SOFT\": \"HARD\"\n",
    "        }\n",
    "\n",
    "    Returns:\n",
    "        The 2018 dataframe, with the `Compound` column overwritten with relative compound names.\n",
    "    \"\"\"\n",
    "    compounds_2018 = compound_selection[\"2018\"]\n",
    "\n",
    "    def convert_compound(row):\n",
    "        index_to_compound = {0: \"SOFT\", 1: \"MEDIUM\", 2: \"HARD\"}\n",
    "\n",
    "        try:\n",
    "            if row.loc[\"Compound\"] not in visual_config[\"slick_names\"][\"18\"]:\n",
    "                return row.loc[\"Compound\"]\n",
    "            else:\n",
    "                return index_to_compound[\n",
    "                    compounds_2018[str(row.loc[\"RoundNumber\"])].index(\n",
    "                        row.loc[\"Compound\"]\n",
    "                    )\n",
    "                ]\n",
    "        except KeyError:\n",
    "            # error handling for when compound_selection.toml is not up-to-date\n",
    "            logging.error(\n",
    "                \"Compound selection record is missing for 2018 season round \"\n",
    "                + str(row.loc[\"RoundNumber\"])\n",
    "            )\n",
    "\n",
    "            # terminate cell\n",
    "            assert False\n",
    "\n",
    "    df_laps[\"Compound\"] = df_laps.apply(convert_compound, axis=1)\n",
    "\n",
    "    return df_laps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Timing Columns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *representative lap time* is calculated by finding the median of the laps that meet the following condition:\n",
    "\n",
    "- Raced on slick tyres (`IsSlick = True`).\n",
    "- `IsAccurate = True`, see definition [here](https://theoehrly.github.io/Fast-F1/core.html#fastf1.core.Laps)\n",
    "- Is completed under green flag (`TrackStatus == 1`), note that this definition is stricter than the one used for `IsAccurate`\n",
    "\n",
    "Define *valid laps* as the laps that meet all above conditions. This is recorded in the new `IsValid` column.\n",
    "\n",
    "The fastest lap time for the session is the fastest time out of the laps where `IsPersonalBest = True` ([definition](https://theoehrly.github.io/Fast-F1/core.html#laps)). Note that this is the same definiton used by the FastF1 `pick_fastest()` method.\n",
    "\n",
    "Using these two times as benchmarks, the following columns are added:\n",
    "\n",
    "- `DeltaToRep`\n",
    "- `DeltaToFastest`\n",
    "- `PctFromRep`\n",
    "- `PctFromFastest`\n",
    "\n",
    "**Caveat**: Metrics are invalid for wet races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_is_valid(df_laps: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add a `IsValid` column in place to identify fast laps.\n",
    "\n",
    "    A valid lap is defined as one that is:\n",
    "        - ran on slick tyres\n",
    "        - fits FastF1's definition for accurate laps\n",
    "        - ran under green flag conditions\n",
    "\n",
    "    Requires:\n",
    "        df_laps has the following columns: [`IsSlick`, `IsAccurate`, `TrackStatus`]\n",
    "    \"\"\"\n",
    "\n",
    "    def check_lap_valid(row):\n",
    "        return (\n",
    "            row.loc[\"IsSlick\"] and row.loc[\"IsAccurate\"] and row.loc[\"TrackStatus\"] == 1\n",
    "        )\n",
    "\n",
    "    df_laps[\"IsValid\"] = df_laps.apply(check_lap_valid, axis=1)\n",
    "\n",
    "    return df_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rep_times(df_laps: pd.DataFrame) -> dict[int, float]:\n",
    "    \"\"\"Find the medians of all valid laptimes by round number.\n",
    "\n",
    "    Requires:\n",
    "        df_laps has the following columns: [`RoundNumber`, `IsValid`, `LapTime`]\n",
    "    \"\"\"\n",
    "    rounds = df_laps[\"RoundNumber\"].unique()\n",
    "    rep_times = {}\n",
    "\n",
    "    for round_number in rounds:\n",
    "        median = df_laps[\n",
    "            (df_laps[\"RoundNumber\"] == round_number) & (df_laps[\"IsValid\"] == True)\n",
    "        ][\"LapTime\"].median()\n",
    "        rep_times[round_number] = round(median, 3)\n",
    "\n",
    "    return rep_times\n",
    "\n",
    "\n",
    "def add_rep_deltas(df_laps: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add two columns that calculate the difference to the representative lap time.\n",
    "\n",
    "    `DeltaToRep` contains the difference to the representative lap time in second.\n",
    "\n",
    "    `PctFromRep` contains the difference to the representative lap time as a percentage of the representative lap time.\n",
    "\n",
    "    Requires:\n",
    "        df_laps has the following columns: [`RoundNumber`, `IsValid`, `LapTime`]\n",
    "    \"\"\"\n",
    "    rep_times = find_rep_times(df_laps)\n",
    "\n",
    "    def delta_to_rep(row):\n",
    "        return row.loc[\"LapTime\"] - rep_times[row.loc[\"RoundNumber\"]]\n",
    "\n",
    "    def pct_from_rep(row):\n",
    "        delta = row.loc[\"LapTime\"] - rep_times[row.loc[\"RoundNumber\"]]\n",
    "        return round(delta / rep_times[row.loc[\"RoundNumber\"]] * 100, 3)\n",
    "\n",
    "    df_laps[\"DeltaToRep\"] = df_laps.apply(delta_to_rep, axis=1)\n",
    "    df_laps[\"PctFromRep\"] = df_laps.apply(pct_from_rep, axis=1)\n",
    "\n",
    "    return df_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fastest_times(df_laps: pd.DataFrame) -> dict[int, float]:\n",
    "    \"\"\"Find the fastest, non-deleted lap times by round.\n",
    "\n",
    "    The fastest lap time per round is inferred by taking the min of individual drivers' fastest laps, which already exclude deleted lap times.\n",
    "\n",
    "    Requires:\n",
    "        df_laps has the following columns: [`RoundNumber`, `IsPersonalBest`, `LapTime`]\n",
    "    \"\"\"\n",
    "    rounds = df_laps[\"RoundNumber\"].unique()\n",
    "    fastest_times = {}\n",
    "\n",
    "    for round_number in rounds:\n",
    "        fastest = df_laps[\n",
    "            (df_laps[\"RoundNumber\"] == round_number)\n",
    "            & (df_laps[\"IsPersonalBest\"] == True)\n",
    "        ][\"LapTime\"].min()\n",
    "        fastest_times[round_number] = round(fastest, 3)\n",
    "\n",
    "    return fastest_times\n",
    "\n",
    "\n",
    "def add_fastest_deltas(df_laps: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add two columns that calculate the difference to the fastest lap time.\n",
    "\n",
    "    `DeltaToFastest` contains the difference to the fastest lap time in second.\n",
    "\n",
    "    `PctFromFastest` contains the difference to the fastest lap time as a percentage of the fastest lap time.\n",
    "\n",
    "    Requires:\n",
    "        df_laps has the following columns: [`RoundNumber`, `LapTime`]\n",
    "    \"\"\"\n",
    "    fastest_times = find_fastest_times(df_laps)\n",
    "\n",
    "    def delta_to_fastest(row):\n",
    "        return row.loc[\"LapTime\"] - fastest_times[row.loc[\"RoundNumber\"]]\n",
    "\n",
    "    def pct_from_fastest(row):\n",
    "        delta = row.loc[\"LapTime\"] - fastest_times[row.loc[\"RoundNumber\"]]\n",
    "        return round(delta / fastest_times[row.loc[\"RoundNumber\"]] * 100, 3)\n",
    "\n",
    "    df_laps[\"DeltaToFastest\"] = df_laps.apply(delta_to_fastest, axis=1)\n",
    "    df_laps[\"PctFromFastest\"] = df_laps.apply(pct_from_fastest, axis=1)\n",
    "\n",
    "    return df_laps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track evolution and diminishing fuel load have significant influences on lap times.\n",
    "\n",
    "The following columns are added to control for these confounding factors. Instead of comparing the lap times to a representative time for the entire event, they will be compared against a representative time at the same stage of the Grand Prix:\n",
    "\n",
    "- `DeltaToLapRep`\n",
    "- `PctFromLapRep`\n",
    "\n",
    "A lap representative time for some lap X is found by computing the median of the laps that meet the following conditions:\n",
    "- Have the same lap number as X\n",
    "- `IsAccurate` = True\n",
    "\n",
    "Note that this set of conditions is less strict than the set used for `DeltaToRep` and `PctFromRep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lap_reps(df_laps: pd.DataFrame) -> dict[int, dict[int, float]]:\n",
    "    \"\"\"Find the rows present in all_laps but missing in transformed_laps.\n",
    "\n",
    "    Args:\n",
    "        items: list of key value pairs where:\n",
    "        the key is the type of the dataframe (either all or transformed)\n",
    "        the value is the dataframe object\n",
    "\n",
    "    Assumes:\n",
    "        - all_laps have at least as many rows as transformed_laps\n",
    "        - The ith row in transformed_laps correspond to the ith row in all_laps\n",
    "\n",
    "    Returns:\n",
    "        The part of all_laps that is missing in transformed_laps.\n",
    "    \"\"\"\n",
    "    lap_reps = {}\n",
    "\n",
    "    for round_number in df_laps[\"RoundNumber\"].unique():\n",
    "        round_lap_reps = {}\n",
    "        round_laps = df_laps[df_laps[\"RoundNumber\"] == round_number]\n",
    "        lap_numbers = round_laps[\"LapNumber\"].unique()\n",
    "\n",
    "        for lap_number in lap_numbers:\n",
    "            median = round_laps[round_laps[\"LapNumber\"] == lap_number][\n",
    "                \"LapTime\"\n",
    "            ].median()\n",
    "            round_lap_reps[lap_number] = round(median, 3)\n",
    "\n",
    "        lap_reps[round_number] = round_lap_reps\n",
    "\n",
    "    return lap_reps\n",
    "\n",
    "\n",
    "def add_lap_rep_deltas(df_laps: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add two columns that calculate the difference to the lap representative time.\n",
    "\n",
    "    `DeltaToLapRep` contains the difference to the lap rep time in second.\n",
    "\n",
    "    `PctFromLapRep` contains the difference to the lap rep time as a percentage of the lap rep time.\n",
    "\n",
    "    Requires:\n",
    "        df_laps has the following columns: [`RoundNumber`, `LapTime`]\n",
    "    \"\"\"\n",
    "    lap_reps = find_lap_reps(df_laps)\n",
    "\n",
    "    def delta_to_lap_rep(row):\n",
    "        return (\n",
    "            row.loc[\"LapTime\"] - lap_reps[row.loc[\"RoundNumber\"]][row.loc[\"LapNumber\"]]\n",
    "        )\n",
    "\n",
    "    def pct_from_lap_rep(row):\n",
    "        delta = (\n",
    "            row.loc[\"LapTime\"] - lap_reps[row.loc[\"RoundNumber\"]][row.loc[\"LapNumber\"]]\n",
    "        )\n",
    "        return round(\n",
    "            delta / lap_reps[row.loc[\"RoundNumber\"]][row.loc[\"LapNumber\"]] * 100, 3\n",
    "        )\n",
    "\n",
    "    df_laps[\"DeltaToLapRep\"] = df_laps.apply(delta_to_lap_rep, axis=1)\n",
    "    df_laps[\"PctFromLapRep\"] = df_laps.apply(pct_from_lap_rep, axis=1)\n",
    "\n",
    "    return df_laps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(items):\n",
    "    \"\"\"\n",
    "    Find the rows present in all_laps but missing in transformed_laps\n",
    "    for a given season\n",
    "\n",
    "    Args:\n",
    "        items: list\n",
    "        list derived from a dict_items object containing all key value\n",
    "        pairs in a key in the return value of load_laps()\n",
    "\n",
    "        i.e all dataframes associated with a certain F1 season\n",
    "\n",
    "    Assumes:\n",
    "        all_laps have at least as many rows as transformed_laps\n",
    "        The ith row in transformed_laps correspond to the ith row in all_laps\n",
    "    \"\"\"\n",
    "\n",
    "    if len(items) == 1:\n",
    "        # If there is only one pair, the key should be \"all\"\n",
    "        assert items[0][0] == \"all\"\n",
    "\n",
    "        logging.info(\"No transfromed_laps found\")\n",
    "\n",
    "        # If no transformed_laps is found, the entirety of all_laps is in the diff\n",
    "        return items[0][1]\n",
    "\n",
    "    elif len(items) == 2:\n",
    "        # \"all\" should be the key for the first pair in items\n",
    "        # but we will not rely on this\n",
    "\n",
    "        num_row_all = 0\n",
    "        num_row_transformed = 0\n",
    "        diff = pd.DataFrame()\n",
    "\n",
    "        if items[0][0] == \"all\":\n",
    "            num_row_all = items[0][1].shape[0]\n",
    "            num_row_transformed = items[1][1].shape[0]\n",
    "            diff = items[0][1]\n",
    "        elif items[0][0] == \"transformed\":\n",
    "            num_row_all = items[1][1].shape[0]\n",
    "            num_row_transformed = items[0][1].shape[0]\n",
    "            diff = items[1][1]\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected key\")\n",
    "\n",
    "        # see assumption\n",
    "        assert num_row_all >= num_row_transformed\n",
    "\n",
    "        if num_row_all == num_row_transformed:\n",
    "            logging.info(\"transformed_laps is up-to-date\")\n",
    "        else:\n",
    "            logging.info(\n",
    "                f\"{num_row_all - num_row_transformed} rows will be added to transformed_laps\"\n",
    "            )\n",
    "\n",
    "        return diff.iloc[num_row_transformed:]\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected input length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_laps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for season, dfs in data.items():\n",
    "    logging.info(str(season) + \":\")\n",
    "    df_transform = find_diff(list(dfs.items()))\n",
    "\n",
    "    if df_transform.shape[0] != 0:\n",
    "        add_is_slick(season, df_transform)\n",
    "        add_compound_name(df_transform, compound_selection[str(season)], season)\n",
    "\n",
    "        if season == 2018:\n",
    "            convert_compound(df_transform)\n",
    "\n",
    "        add_is_valid(df_transform)\n",
    "        add_rep_deltas(df_transform)\n",
    "        add_fastest_deltas(df_transform)\n",
    "        add_lap_rep_deltas(df_transform)\n",
    "\n",
    "        path = parent_path / \"Data\" / f\"transformed_laps_{season}.csv\"\n",
    "\n",
    "        if Path.is_file(path):\n",
    "            # if the file already exists, then don't need to write header again\n",
    "            # need to move the cursor onto a new line before appending\n",
    "            with open(path, \"a\") as csv:\n",
    "                csv.write(\"\\n\")\n",
    "                df_transform.to_csv(path, mode=\"a\", header=False, index=False)\n",
    "        else:\n",
    "            df_transform.to_csv(path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "e78b6b4158d8f577a77be3bef6c4f5889b406541923fa59adc2e6c48950512fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
