{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastf1 as f\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import tomli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/compound_selection.toml\", \"rb\") as toml:\n",
    "    compound_selection = tomli.load(toml)\n",
    "with open(\"Data/visualization_config.toml\", \"rb\") as toml:\n",
    "    visual_config = tomli.load(toml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = os.getcwd() + \"/Cache\"\n",
    "f.Cache.enable_cache(cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress SettingWithCopy Warning\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    '''\n",
    "    Read csv file at path location and filter for relevant columns\n",
    "\n",
    "    Requires:\n",
    "    csv file located at path location is derived from a fastf1 laps object\n",
    "    '''\n",
    "\n",
    "    return pd.read_csv(path, \n",
    "                       header=0, \n",
    "                       true_values=[\"TRUE\"], \n",
    "                       false_values=[\"FALSE\"],\n",
    "                       usecols=[\"Time\", \"DriverNumber\", \"LapTime\", \"LapNumber\", \"Stint\", \n",
    "                                \"PitOutTime\", \"PitInTime\", \"IsPersonalBest\", \"Compound\", \"TyreLife\", \"FreshTyre\", \n",
    "                                \"Team\", \"Driver\", \"TrackStatus\", \"IsAccurate\", \"RoundNumber\", \n",
    "                                \"EventName\"]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_dtype(df_laps):\n",
    "    '''\n",
    "    Requires: \n",
    "    df_laps has the following columns: [\"Time\", \"LapTime\", \"PitInTime\", \"PitOutTime\", \"IsPersonalBest\"]\n",
    "    '''\n",
    "\n",
    "    # convert from object (string) to timedelta\n",
    "    df_laps[[\"Time\", \"LapTime\", \"PitInTime\", \"PitOutTime\"]] = df_laps[[\"Time\", \"LapTime\", \"PitInTime\", \"PitOutTime\"]].apply(pd.to_timedelta)\n",
    "    df_laps[\"LapTime\"] = df_laps[\"LapTime\"].apply(lambda x: x.total_seconds())\n",
    "\n",
    "    # convert from object (string) to bool\n",
    "    # treat missing entries as False\n",
    "    df_laps[\"IsPersonalBest\"] = df_laps[\"IsPersonalBest\"].fillna(value=\"False\")\n",
    "    df_laps[\"IsPersonalBest\"] = df_laps[\"IsPersonalBest\"].astype(bool)\n",
    "\n",
    "    return df_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_compound(df_laps):\n",
    "    df_laps[\"Compound\"] = df_laps[\"Compound\"].fillna(value=\"UNKNOWN\")\n",
    "\n",
    "    return df_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_laps():\n",
    "    df_dict = {}\n",
    "    data_files = [file for file in os.listdir(\"Data\") if os.path.isfile(\"Data/\"+file)]\n",
    "\n",
    "    for file in data_files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            splits = file.split(\"_\")\n",
    "            \n",
    "            # \"all\" or \"transformed\"\n",
    "            type = splits[0]\n",
    "\n",
    "            season = file.split(\"_\")[2]\n",
    "            season = int(season[:season.find(\".\")])\n",
    "\n",
    "            df = read_csv(\"Data/\" + file)\n",
    "\n",
    "            if file.startswith(\"all\"):\n",
    "                correct_dtype(df)\n",
    "                fill_compound(df)\n",
    "\n",
    "            if season not in df_dict:\n",
    "                df_dict[season] = {}\n",
    "                \n",
    "            df_dict[season][type] = df\n",
    "\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Tyre Information Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_is_slick(season, df_laps):\n",
    "    '''\n",
    "    Requires:\n",
    "    df_laps has the following column: [\"Compound\"]\n",
    "    '''\n",
    "\n",
    "    slick_names = []\n",
    "\n",
    "    if season == 2018:\n",
    "        slick_names = visual_config[\"slick_names\"][\"18\"]\n",
    "    else:\n",
    "        slick_names = visual_config[\"slick_names\"][\"19_\"]\n",
    "    \n",
    "    df_laps[\"IsSlick\"] = df_laps[\"Compound\"].apply(lambda x: x in slick_names)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastF1 provides relative compound information (soft, medium, hard) as the `Compound` column in its `Laps` objects\n",
    "\n",
    "The actual compound names (C1, C2, C3 etc. or ultrasoft, supersoft etc.) needs to be added to maintain consistency. These will be recorded in the `CompoundName` column.\n",
    "\n",
    "For the 2018 season, the `Compound` column already records the actual compound names. The `CompoundName` column will still be added for consistency.\n",
    "\n",
    "To further ensure consistency, the 2018 `Compound` column will be converted so it also has the (soft, medium, hard) representation. **Before** this transformation is applied, the 2018 `Compound` and `CompoundName` columns are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_compound_name(df_laps, compound_selection, season):\n",
    "    '''\n",
    "    Requires:\n",
    "    df_laps has the following columns: [\"Compound\", \"RoundNumber\"]\n",
    "\n",
    "    Assumes:\n",
    "        - all data contained in compound_selection is from the same season \n",
    "        - df_laps contain data from the same season as compound_selection\n",
    "    '''\n",
    "    if season == 2018:\n",
    "        df_laps[\"CompoundName\"] = df_laps[\"Compound\"]\n",
    "\n",
    "        return df_laps\n",
    "    \n",
    "    def convert_compound_name(row):\n",
    "        compound_to_index = {\"SOFT\":2, \"MEDIUM\":1, \"HARD\":0}\n",
    "\n",
    "        try:\n",
    "            if row.loc[\"Compound\"] not in compound_to_index:\n",
    "                return row.loc[\"Compound\"]\n",
    "            else:\n",
    "                return compound_selection[str(row.loc[\"RoundNumber\"])][compound_to_index[row.loc[\"Compound\"]]]\n",
    "        except KeyError:\n",
    "            # error handling for when compound_selection.toml is not up-to-date\n",
    "            print(\"Compound selection record is missing for round \" + str(row.loc[\"RoundNumber\"]))\n",
    "\n",
    "            # terminate cell \n",
    "            assert False\n",
    "\n",
    "    df_laps[\"CompoundName\"] = df_laps.apply(convert_compound_name, axis=1)\n",
    "\n",
    "    return df_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_compound(df_laps):\n",
    "    '''\n",
    "    Requires:\n",
    "        df_laps must be the 2018 dataset\n",
    "        df_laps has the following columns: [\"Compound\", \"RoundNumber\"]\n",
    "    '''\n",
    "\n",
    "    compounds_2018 = compound_selection[\"2018\"]\n",
    "\n",
    "    def convert_compound(row):\n",
    "        index_to_compound = {0:\"SOFT\", 1:\"MEDIUM\", 2:\"HARD\"}\n",
    "        \n",
    "        try:\n",
    "            if row.loc[\"Compound\"] not in visual_config[\"slick_names\"][\"18\"]:\n",
    "                return row.loc[\"Compound\"]\n",
    "            else:\n",
    "                return index_to_compound[compounds_2018[str(row.loc[\"RoundNumber\"])].index(row.loc[\"Compound\"])]\n",
    "        except KeyError:\n",
    "            # error handling for when compound_selection.toml is not up-to-date\n",
    "            print(\"Compound selection record is missing for 2018 season round \" + str(row.loc[\"RoundNumber\"]))\n",
    "\n",
    "            # terminate cell \n",
    "            assert False\n",
    "    \n",
    "    df_laps[\"Compound\"] = df_laps.apply(convert_compound, axis=1)\n",
    "\n",
    "    return df_laps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Timing Columns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Driver grid position is inferred from the `Time` column. FastF1 documentation defines this column as \"Session time when the lap time was set (end of lap)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pos(df_laps):\n",
    "    df_laps[\"rank\"] = pd.Series(dtype=\"int\")\n",
    "\n",
    "    for round in range(1, int(df_laps[\"RoundNumber\"].max()) + 1):\n",
    "        df_round = df_laps[df_laps[\"RoundNumber\"] == round]\n",
    "        \n",
    "        for lap in range(1, int(df_round[\"LapNumber\"].max()) + 1):\n",
    "            ranks = df_test[(df_test[\"LapNumber\"] == lap) & (df_test[\"RoundNumber\"] == 16)][\"Time\"].rank(method=\"first\")\n",
    "            df_test.iloc[ranks.index, df_test.columns.get_loc(\"rank\")] = ranks.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *representative lap time* is calculated by finding the median of the laps that meet the following condition:\n",
    "\n",
    "- Raced on slick tyres (`IsSlick = True`).\n",
    "- `IsAccurate = True`, see definition [here](https://theoehrly.github.io/Fast-F1/core.html#fastf1.core.Laps)\n",
    "- Is completed under green flag (`TrackStatus == 1`), note that this definition is stricter than the one used for `IsAccurate`\n",
    "\n",
    "Define *valid laps* as the laps that meet all above conditions. This is recorded in the new `IsValid` column.\n",
    "\n",
    "The fastest lap time for the session is the fastest time out of the laps where `IsPersonalBest = True` ([definition](https://theoehrly.github.io/Fast-F1/core.html#laps)). Note that this is the same definiton used by the FastF1 `pick_fastest()` method.\n",
    "\n",
    "Using these two times as benchmarks, the following columns are added:\n",
    "\n",
    "- `DeltaToRep`\n",
    "- `DeltaToFastest`\n",
    "- `PctFromRep`\n",
    "- `PctFromFastest`\n",
    "\n",
    "**Caveat**: Metrics are invalid for wet races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_is_valid(df_laps):\n",
    "    '''\n",
    "    Requires:\n",
    "    df_laps has the following columns: [\"IsSlick\", \"IsAccurate\", \"TrackStatus\"]\n",
    "    '''\n",
    "\n",
    "    def check_lap_valid(row):\n",
    "        return row.loc[\"IsSlick\"] and row.loc[\"IsAccurate\"] and row.loc[\"TrackStatus\"] == 1\n",
    "\n",
    "    df_laps[\"IsValid\"] = df_laps.apply(check_lap_valid, axis=1)\n",
    "\n",
    "    return df_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rep_times(df_laps):\n",
    "    '''\n",
    "    Requires:\n",
    "    df_laps has the following columns: [\"RoundNumber\", \"IsValid\", \"LapTime\"]\n",
    "    '''\n",
    "\n",
    "    rounds = df_laps[\"RoundNumber\"].unique()\n",
    "    rep_times = {}\n",
    "\n",
    "    for round_number in rounds:\n",
    "        median = df_laps[(df_laps[\"RoundNumber\"] == round_number) & (df_laps[\"IsValid\"] == True)][\"LapTime\"].median()\n",
    "        rep_times[round_number] = round(median, 3)\n",
    "\n",
    "    return rep_times\n",
    "\n",
    "def add_rep_deltas(df_laps):\n",
    "    '''\n",
    "    Requires:\n",
    "    df_laps has the following columns: [\"RoundNumber\", \"IsValid\", \"LapTime\"]\n",
    "    '''\n",
    "\n",
    "    rep_times = find_rep_times(df_laps)\n",
    "    \n",
    "    def delta_to_rep(row):\n",
    "        return row.loc[\"LapTime\"] - rep_times[row.loc[\"RoundNumber\"]]\n",
    "\n",
    "    def pct_from_rep(row):\n",
    "        delta = row.loc[\"LapTime\"] - rep_times[row.loc[\"RoundNumber\"]]\n",
    "        return round(delta / rep_times[row.loc[\"RoundNumber\"]] * 100, 3)\n",
    "\n",
    "    df_laps[\"DeltaToRep\"] = df_laps.apply(delta_to_rep, axis=1)\n",
    "    df_laps[\"PctFromRep\"] = df_laps.apply(pct_from_rep, axis=1)\n",
    "\n",
    "    return df_laps\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fastest_times(df_laps):\n",
    "    '''\n",
    "    Requires:\n",
    "    df_laps has the following columns: [\"RoundNumber\", \"IsPersonalBest\", \"LapTime\"]\n",
    "    '''\n",
    "\n",
    "    rounds = df_laps[\"RoundNumber\"].unique()\n",
    "    fastest_times = {}\n",
    "\n",
    "    for round_number in rounds:\n",
    "        fastest = df_laps[(df_laps[\"RoundNumber\"] == round_number) & (df_laps[\"IsPersonalBest\"] == True)][\"LapTime\"].min()\n",
    "        fastest_times[round_number] = round(fastest, 3)\n",
    "    \n",
    "    return fastest_times\n",
    "\n",
    "def add_fastest_deltas(df_laps):\n",
    "    '''\n",
    "    Requires:\n",
    "    df_laps has the following columns: [\"RoundNumber\", \"IsPersonalBest\", \"LapTime\"]\n",
    "    '''\n",
    "\n",
    "    fastest_times = find_fastest_times(df_laps)\n",
    "    \n",
    "    def delta_to_fastest(row):\n",
    "        return row.loc[\"LapTime\"] - fastest_times[row.loc[\"RoundNumber\"]]\n",
    "\n",
    "    def pct_from_fastest(row):\n",
    "        delta = row.loc[\"LapTime\"] - fastest_times[row.loc[\"RoundNumber\"]]\n",
    "        return round(delta / fastest_times[row.loc[\"RoundNumber\"]] * 100, 3)\n",
    "\n",
    "    df_laps[\"DeltaToFastest\"] = df_laps.apply(delta_to_fastest, axis=1)\n",
    "    df_laps[\"PctFromFastest\"] = df_laps.apply(pct_from_fastest, axis=1)\n",
    "\n",
    "    return df_laps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track evolution and diminishing fuel load have significant influences on lap times.\n",
    "\n",
    "The following columns are added to control for these confounding factors. Instead of comparing the lap times to a representative time for the entire event, they will be compared against a representative time at the same stage of the Grand Prix:\n",
    "\n",
    "- `DeltaToLapRep`\n",
    "- `PctFromLapRep`\n",
    "\n",
    "A lap representative time for some lap X is found by computing the median of the laps that meet the following conditions:\n",
    "- Have the same lap number as X\n",
    "- `IsAccurate` = True\n",
    "\n",
    "Note that this set of conditions is less strict than the set used for `DeltaToRep` and `PctFromRep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lap_reps(df_laps):\n",
    "    '''\n",
    "    Requires:\n",
    "    df_laps has the following columns: [\"RoundNumber\", \"LapNumber\", \"IsValid\", \"LapTime\"]\n",
    "    '''\n",
    "    \n",
    "    lap_reps = {}\n",
    "\n",
    "    for round_number in df_laps[\"RoundNumber\"].unique():\n",
    "        round_lap_reps = {}\n",
    "        round_laps = df_laps[df_laps[\"RoundNumber\"] == round_number]\n",
    "        lap_numbers = round_laps[\"LapNumber\"].unique()\n",
    "\n",
    "        for lap_number in lap_numbers:\n",
    "            median = round_laps[round_laps[\"LapNumber\"] == lap_number][\"LapTime\"].median()\n",
    "            round_lap_reps[lap_number] = round(median, 3)\n",
    "        \n",
    "        lap_reps[round_number] = round_lap_reps\n",
    "\n",
    "    return lap_reps\n",
    "\n",
    "def add_lap_rep_deltas(df_laps):\n",
    "    '''\n",
    "    Requires:\n",
    "    df_laps has the following columns: [\"RoundNumber\", \"LapNumber\", \"IsValid\", \"LapTime\"]\n",
    "    '''\n",
    "\n",
    "    lap_reps = find_lap_reps(df_laps)\n",
    "\n",
    "    def delta_to_lap_rep(row):\n",
    "        return row.loc[\"LapTime\"] - lap_reps[row.loc[\"RoundNumber\"]][row.loc[\"LapNumber\"]]\n",
    "\n",
    "    def pct_from_lap_rep(row):\n",
    "        delta = row.loc[\"LapTime\"] - lap_reps[row.loc[\"RoundNumber\"]][row.loc[\"LapNumber\"]]\n",
    "        return round(delta / lap_reps[row.loc[\"RoundNumber\"]][row.loc[\"LapNumber\"]] * 100, 3)\n",
    "\n",
    "    df_laps[\"DeltaToLapRep\"] = df_laps.apply(delta_to_lap_rep, axis=1)\n",
    "    df_laps[\"PctFromLapRep\"] = df_laps.apply(pct_from_lap_rep, axis=1)\n",
    "\n",
    "    return df_laps\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(items):\n",
    "    '''\n",
    "    Find the rows present in all_laps but missing in transformed_laps \n",
    "    for a given season\n",
    "\n",
    "    Args:\n",
    "        items: list\n",
    "        list derived from a dict_items object containing all key value \n",
    "        pairs in a key in the return value of load_laps()\n",
    "\n",
    "        i.e all dataframes associated with a certain F1 season\n",
    "\n",
    "    Assumes:\n",
    "        all_laps have at least as many rows as transformed_laps\n",
    "        The ith row in transformed_laps correspond to the ith row in all_laps\n",
    "    '''\n",
    "\n",
    "    if len(items) == 1:\n",
    "        # If there is only one pair, the key should be \"all\"\n",
    "        assert items[0][0] == \"all\"\n",
    "\n",
    "        print(\"No transfromed_laps found\")\n",
    "\n",
    "        # If no transformed_laps is found, the entirety of all_laps is in the diff\n",
    "        return items[0][1]\n",
    "\n",
    "    elif len(items) == 2:\n",
    "        # \"all\" should be the key for the first pair in items\n",
    "        # but we will not rely on this\n",
    "\n",
    "        num_row_all = 0\n",
    "        num_row_transformed = 0\n",
    "        diff = pd.DataFrame()\n",
    "\n",
    "        if items[0][0] == \"all\":\n",
    "            num_row_all = items[0][1].shape[0]\n",
    "            num_row_transformed = items[1][1].shape[0]\n",
    "            diff = items[0][1]\n",
    "        elif items[0][0] == \"transformed\":\n",
    "            num_row_all = items[1][1].shape[0]\n",
    "            num_row_transformed = items[0][1].shape[0]\n",
    "            diff = items[1][1]\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected key\")\n",
    "\n",
    "        # see assumption \n",
    "        assert num_row_all >= num_row_transformed\n",
    "\n",
    "        if num_row_all == num_row_transformed:\n",
    "            print(\"transformed_laps is up-to-date\")\n",
    "        else:\n",
    "            print(F\"{num_row_all - num_row_transformed} rows will be added to transformed_laps\")\n",
    "\n",
    "        return diff.iloc[num_row_transformed:]\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected input length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_laps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for season, dfs in data.items():\n",
    "    print(str(season) + \":\")\n",
    "    df_transform = find_diff(list(dfs.items()))\n",
    "\n",
    "    if df_transform.shape[0] != 0:\n",
    "        add_is_slick(season, df_transform)\n",
    "        add_compound_name(df_transform, compound_selection[str(season)], season)\n",
    "\n",
    "        if season == 2018:\n",
    "            convert_compound(df_transform)\n",
    "\n",
    "        add_is_valid(df_transform)\n",
    "        add_rep_deltas(df_transform)\n",
    "        add_fastest_deltas(df_transform)\n",
    "        add_lap_rep_deltas(df_transform)\n",
    "\n",
    "        path = f\"Data/transformed_laps_{season}.csv\"\n",
    "        \n",
    "        if os.path.isfile(path):\n",
    "            # if the file already exists, then don't need to write header again\n",
    "            # need to move the cursor onto a new line before appending \n",
    "            with open(path, 'a') as append:\n",
    "                append.write(\"\\n\")\n",
    "                \n",
    "            df_transform.to_csv(path, mode=\"a\", header=False)\n",
    "        else:\n",
    "            df_transform.to_csv(path)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "e78b6b4158d8f577a77be3bef6c4f5889b406541923fa59adc2e6c48950512fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
